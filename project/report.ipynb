{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "## Vision\n",
    "The goal for my project is to develop a neural network that can efficiently solve the wumpus world problem. This project would make me explore topics on reinforcement learning and Q-learning. The wumpus world problem is a game that is easy enough to code and be quickly simulated for fast training.\n",
    "\n",
    "I want to create an agent that can learn how to play Wumpus World without any prior data or knowledge of the environment. If time allows, I would like to make the environment dynamic, such as having the Wumpus move around the board.\n",
    "\n",
    "## Background\n",
    "The Wumpus World is a game that requires an agent to navigate a 4x4 cave with limited senses. The objective is to grab the gold and exit the cave while dodging pits and the Wumpus. When researching models for solving such a problem, the [OpenAI Gym](https://openai.com/blog/openai-baselines-dqn/) was a common solution for modeling these environments and training such networks. OpenAI Gym focuses on reinforcement networks, and it has found the most success with a Deep Q Network (DQN). There are many variants of a DQN including Double Q Learning, Prioritized Replay, Dueling DQN. For simplicity, I focused on implementing a basic DQN rather than experimenting with the variants. \n",
    "\n",
    "DQNs are a new type of network structue that we have not previously explored in class. But it wasn't very hard to find a variety of articles on the subject. Starting from the source, OpenAI Gym states how difficult reinforcement learning (RL) can be because noisy performance can lead to many unreproducable results. But researchers at DeepMind found DQNs to provide the best performance in RL problems. \n",
    "\n",
    "Naturally, understanding how DQN works is an essential step in the process. One the better articles on the subject that I found was [Reinforcement Learning w/ Keras + OpenAI: DQNs](https://towardsdatascience.com/reinforcement-learning-w-keras-openai-dqns-1eed3a5338c). This article provided a lot of high-level information and implementation on the subject that I could easily reproduce within my environment. This one sentence from the article is a great intro to the topic:\n",
    "\n",
    "> \"Q-learning (which doesn’t stand for anything, by the way) is centered around creating a “virtual table” that accounts for how much reward is assigned to each possible action given the current state of the environment.\"\n",
    " \n",
    "Essentially, for any given situation or state of the world, there will be a table of values that map a theoretical Q-score to each action. In the [Reinforcement Learning (DQN) Tutorial](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html), PyTorch provides a good description of the DQN algorithm and training process. The first important aspect of DQN trainging is the replay memory. This collection of data stores the transitions that an agent observes (state -> action -> new state + reward). By randomly sampling from this memory, the DQN can use this data as a means for training. The DQN algorithm basically states that if we had a function $$Q* : State \\times  Action \\rightarrow R$$ that could tell us what our return would be, we could use that in any given state to predict which action we should take for maximizing score. Since this function doesn't exist, we train our network to resemble Q*. To minimise the error within the network, DQN uses a Huber loss on the temporal difference error on the function $$ \\beta = Q(s, a) - (r + \\gamma maxQ(s', a))$$ This error basically represents the difference between the predicted and target state values.\n",
    "\n",
    "With the memory and training structures in place, we can begin to work with our model and its hyper parameters. The first step the model takes is acting. The exploratory or epsilon hyper parameter is the probability that the agent chooses a random action rather than the one predicted by the network. This allows the agent to explore the world early on so it can build memory with a variety of actions and consequences. Epsilon decay is another hyper parameter that decreases the epsilon over training so that the agent slowly starts to use its predicted actions more often. Once the action has been taking in the environment, the agent remembers the whole transition (state -> action -> new state + reward). Then is enters the replay training step. In this step, the agent uses the acculated memory to randomly sample transitions and predict their outcomes. Using the training algorithm previously discussed, the agent trains itself on its past experience. Depending on the complexity of the environment, this bootstrapping can either work quickly or slowly. The unique and cool feature of DQNs is that we don't necessarily need any previous training data, we simply generate it ourselves.\n",
    "\n",
    "In the previously mentioned [Reinforcement Learning w/ Keras + OpenAI: DQNs](https://towardsdatascience.com/reinforcement-learning-w-keras-openai-dqns-1eed3a5338c), the author uses two identical networks, one called the model and the other target model. The hyper parameter tau tells how quickly the target model moves towards the model. This technique appears to match the Double Q Learning model presented in the [OpenAI Gym](https://openai.com/blog/openai-baselines-dqn/) article. This technique basically corrects any overestimatations made by the model, retaining what has been learned in the target model. By setting the tau value to 1, we once again have a simple DQN model.\n",
    "\n",
    "I also thought that an RNN network on top of a DQN could be an interesting solution to providing more memory in the system. From this research paper: [Deep Q-Learning with Recurrent Neural Networks](http://cs229.stanford.edu/proj2016/report/ChenYingLaird-DeepQLearningWithRecurrentNeuralNetwords-report.pdf), it seemed that this may be a possibility. But when doing more research on the topic, I would run into post like this: [How does LSTM in deep reinforcement learning differ from experience replay?](https://ai.stackexchange.com/questions/7721/how-does-lstm-in-deep-reinforcement-learning-differ-from-experience-replay), where the top answer basically said they don't work well together. Since the experience replay method randomly samples from past experiences, it doesn't work well in the RNN since the RNN would expected correlated samples.\n",
    "## Implementation\n",
    "I started implementing my system with the Wumpus World environment. I simply inherited from the OpenAI gym environment parent class and implemented all the necessary methods and logic for Wumpus World. One of the convenient aspects of Wumpus World is that it doesn't require any graphics or images. The inputs to the DQN are simply the observations specified within the textbook [Artifical Intelligence: A Modern Approach](http://aima.cs.berkeley.edu/), and the outputs are the list of actions as from the textbook as well. One thing that I did later change from the textbook was that I added the agents position, direction, gold status to the observations. It seems to greatly boost performance and didn't really compromise the problem since it is data that can be tracked in any other algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "from enum import IntEnum\n",
    "import math\n",
    "\n",
    "class Wumpus(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}   \n",
    "    class Board(IntEnum):\n",
    "        NOTHING = 0\n",
    "        PIT = 1\n",
    "        BREEZE = 2\n",
    "        WUMPUS = 3\n",
    "        STENCH = 4\n",
    "        GOLD = 5\n",
    "        PLAYER = 6\n",
    "        EXIT = 7\n",
    "        WALL = 8\n",
    "\n",
    "    class Direction(IntEnum):\n",
    "        UP = 0\n",
    "        LEFT = 1\n",
    "        DOWN = 2\n",
    "        RIGHT = 3\n",
    "\n",
    "    class Actions(IntEnum):\n",
    "        FORWARD = 0\n",
    "        TURNLEFT = 1\n",
    "        TURNRIGHT = 2\n",
    "        GRAB = 3\n",
    "        SHOOT = 4\n",
    "        CLIMB = 5\n",
    "\n",
    "    class Rewards(IntEnum):\n",
    "        EXIT = -500\n",
    "        EXIT_GOLD = 1000\n",
    "        DEATH = -1000\n",
    "        GRAB_GOLD = 500\n",
    "        KILL_WUMPUS = 100\n",
    "        SHOT_ARROW = -10\n",
    "        \n",
    "    def __init__(self, width=4, height=4):\n",
    "        self.w = width\n",
    "        self.h = height\n",
    "        self.player = {\n",
    "            \"position\": 0,\n",
    "            \"direction\": 0, \n",
    "            \"arrow\": True,\n",
    "            \"gold\": False,\n",
    "        }\n",
    "        self.action = 0\n",
    "        self.reward = 0\n",
    "        self.observations = []\n",
    "        self.action_space = spaces.Discrete(6)\n",
    "\n",
    "        self.observation_space = spaces.Tuple((\n",
    "            spaces.Discrete(2),\n",
    "            spaces.Discrete(2),\n",
    "            spaces.Discrete(2),\n",
    "            spaces.Discrete(2),\n",
    "            spaces.Discrete(2),\n",
    "            spaces.Discrete(2),\n",
    "            spaces.Discrete(self.w * self.h),\n",
    "            spaces.Discrete(4),\n",
    "            spaces.Discrete(2),\n",
    "        ))\n",
    "        self._generate()\n",
    "    \n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "        observations = [False] * 9\n",
    "        done = False\n",
    "        reward = -1\n",
    "        # Handle the actions\n",
    "        if action == self.Actions.FORWARD:\n",
    "            position, bump = self._move_forward(self.player[\"position\"], self.player[\"direction\"], self.Board.PLAYER)\n",
    "            observations[3] = bump\n",
    "            self.player[\"position\"] = position\n",
    "        elif action == self.Actions.TURNLEFT:\n",
    "            self.player[\"direction\"] = self._turn_left(self.player[\"direction\"])\n",
    "        elif action == self.Actions.TURNRIGHT:\n",
    "            self.player[\"direction\"] = self._turn_right(self.player[\"direction\"])\n",
    "        elif action == self.Actions.GRAB:\n",
    "            if self.Board.GOLD in self.board[self.player[\"position\"]]:\n",
    "                reward += self.Rewards.GRAB_GOLD\n",
    "                self.player[\"gold\"] = True\n",
    "                self.board[self.player[\"position\"]].remove(self.Board.GOLD)\n",
    "        elif action == self.Actions.SHOOT:\n",
    "            reward += self.Rewards.SHOT_ARROW\n",
    "            hit_something = False\n",
    "            arrow_position = self.player[\"position\"]\n",
    "            # Move the arrow forward until it hits wall or wumpus\n",
    "            while not hit_something:\n",
    "                position, bump = self._move_forward(arrow_position, self.player[\"direction\"])\n",
    "                hit_something = bump\n",
    "                arrow_position = position\n",
    "                if self.Board.WUMPUS in self.board[arrow_position]:\n",
    "                    hit_something = True\n",
    "                    observations[4] = True\n",
    "                    # Remove the Wumpus and stench\n",
    "                    self.board[arrow_position].remove(self.Board.WUMPUS)\n",
    "                    for p in self._get_adjacent(arrow_position):\n",
    "                        self.board[p].remove(self.Board.STENCH)\n",
    "                    reward += self.Rewards.KILL_WUMPUS\n",
    "            pass\n",
    "        elif action == self.Actions.CLIMB:\n",
    "            if self.Board.EXIT in self.board[self.player[\"position\"]]:\n",
    "                reward += self.Rewards.EXIT_GOLD if self.player[\"gold\"] else self.Rewards.EXIT\n",
    "                done = True\n",
    "\n",
    "        # Check if the player died\n",
    "        position = self.board[self.player[\"position\"]]\n",
    "        if self.Board.PIT in position or self.Board.WUMPUS in position:\n",
    "            reward += self.Rewards.DEATH\n",
    "            done = True\n",
    "        observations = self._get_observations(observations)\n",
    "\n",
    "        # Record things for rendering\n",
    "        self.action = action\n",
    "        self.reward = reward\n",
    "        self.observations = observations\n",
    "        \n",
    "        return np.array(observations), reward, done, {}\n",
    "            \n",
    "    def reset(self):\n",
    "        self.player = {\n",
    "            \"position\": 0,\n",
    "            \"direction\": 0,\n",
    "            \"arrow\": True,\n",
    "            \"gold\": False,\n",
    "        }\n",
    "        self._generate();\n",
    "        return self._get_observations()\n",
    "\n",
    "    \n",
    "    def render(self, mode='human', close=False):\n",
    "        out = sys.stdout\n",
    "        for i in range(self.h):\n",
    "            for j in range(self.w):\n",
    "                #out.write(\"\" + np.sum(list(self.board[i * self.h + j])).tostring())\n",
    "                out.write(\"{} \".format(np.sum(list(self.board[i * self.h + j]))))\n",
    "            out.write(\"\\n\")\n",
    "        out.write(\"Action: {}, Reward: {}\\n\".format(self.action, self.reward))\n",
    "        print(self.observations)\n",
    "        for i in range(self.h + 2):\n",
    "            sys.stdout.write(\"\\033[F\")\n",
    "\n",
    "    def _get_observations(self, observations=[False] * 9):\n",
    "        position = self.board[self.player[\"position\"]]\n",
    "        observations[0] = self.Board.STENCH in position\n",
    "        observations[1] = self.Board.BREEZE in position\n",
    "        observations[2] = self.Board.GOLD in position\n",
    "        observations[5] = self.Board.EXIT in position\n",
    "        observations[6] = self.player[\"position\"]\n",
    "        observations[7] = self.player[\"direction\"]\n",
    "        observations[8] = self.player[\"gold\"]\n",
    "        \n",
    "        return observations\n",
    "\n",
    "    def _move_forward(self, position, direction, item=None):\n",
    "        new_position = position\n",
    "        distance = self.h if direction % 2 == 0 else 1\n",
    "        sign = -1 if direction < 2 else 1\n",
    "        move_to = position + (distance * sign)\n",
    "        new_position = move_to if self._valid_move(position, move_to) and self.Board.WALL not in self.board[move_to] else position\n",
    "        if item is not None:\n",
    "            self.board[position].discard(item)\n",
    "            self.board[new_position].add(item)\n",
    "        return new_position, position == new_position\n",
    "\n",
    "    def _valid_move(self, old, new):\n",
    "        old_row = math.floor(old/self.w)\n",
    "        new_row = math.floor(new/self.w)\n",
    "        diff = abs(old - new)\n",
    "        if diff == 1:\n",
    "            return old_row == new_row\n",
    "        elif diff == self.w:\n",
    "            return new_row >= 0 and new_row < self.h\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def _turn_left(self, direction):\n",
    "        return (direction + 1) % 4\n",
    "\n",
    "    def _turn_right(self, direction):\n",
    "        return (direction - 1) % 4\n",
    "\n",
    "    def _is_empty(self, position):\n",
    "        p = self.board[position]\n",
    "        return not (self.Board.PIT in p or self.Board.EXIT in p or self.Board.WALL in p or self.Board.PLAYER in p or self.Board.WUMPUS in p or self.Board.GOLD in p)\n",
    "\n",
    "    def _random_empty_place(self, item=None):\n",
    "        rand = random.randrange(len(self.board))\n",
    "        for i in range(len(self.board)):\n",
    "            p = (rand + i) % len(self.board)\n",
    "            if self._is_empty(p):\n",
    "                if item is not None:\n",
    "                    self.board[p].add(item)\n",
    "                return p \n",
    "        print(\"Failed to place item\")\n",
    "        return -1\n",
    "                \n",
    "    def _get_adjacent(self, position):\n",
    "        adjacent = []\n",
    "        for direction in range(4):\n",
    "            distance = self.h if direction % 2 == 0 else 1\n",
    "            sign = -1 if direction < 2 else 1\n",
    "            move_to = position + (distance * sign)\n",
    "            if self._valid_move(position, move_to):\n",
    "                adjacent.append(move_to)\n",
    "        return adjacent\n",
    "            \n",
    "\n",
    "    def _generate(self):\n",
    "        self.board = [{0} for _ in range(self.h * self.w)]\n",
    "\n",
    "        # Add the player and the exit\n",
    "        start_position = 12\n",
    "        self.board[start_position].add(self.Board.PLAYER)\n",
    "        self.board[start_position].add(self.Board.EXIT)\n",
    "        self.player[\"position\"] = start_position\n",
    "\n",
    "        # Add the Wumpus\n",
    "        wumpus_position = self._random_empty_place()\n",
    "        self.board[wumpus_position].add(self.Board.WUMPUS)\n",
    "        for p in self._get_adjacent(wumpus_position):\n",
    "            self.board[p].add(self.Board.STENCH)\n",
    "\n",
    "        # Add the pits\n",
    "        for i in range(len(self.board)):\n",
    "            if random.uniform(0, 1) < 0.1:\n",
    "                # Only add a whole if it is empty\n",
    "                if (self._is_empty(i)):\n",
    "                    self.board[i].add(self.Board.PIT)\n",
    "                    for p in self._get_adjacent(i):\n",
    "                        self.board[p].add(self.Board.BREEZE)\n",
    "                    \n",
    "        # Place the gold at a random spot\n",
    "        self._random_empty_place(self.Board.GOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I implemented the agent and training method. I used [Reinforcement Learning w/ Keras + OpenAI: DQNs](https://towardsdatascience.com/reinforcement-learning-w-keras-openai-dqns-1eed3a5338c) as a structure for my DQN code and later added the Double Q Learning model from the article to see if it improved my performance. Throughout the process of creating the environment, I tried training on many different configurations such as exit and gold only to see how well the agent could learn those environments. I created a simple terminal rendering of the 4x4 grid that simply diplayed the board state numerically. This was for a debugging interface, not really a visual.\n",
    "\n",
    "I took some other liberties as well with the project. One example is that I lowered the spawn probability of pits from 0.2 to 0.1. I my early iterations of training, the bot always died and didn't seem to learn much of the environment, opting to always exit the room immediately.\n",
    "\n",
    "The rewards were another difficult aspect of implementing the environment. The basic rewards given in the textbook are probably the most optimal, but I would run into annoying behaviors where the agent would exit immediately to cut its losses of dying in a pit. I ended up adding two extra weights to Wumpus World. First is -500 reward for exiting the cave without the gold. Second, a 500 reward for grabbing the gold. Both these additional weights encourage the agent to explore the world. Third, a 100 reward for killing the Wumpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import Huber\n",
    "# https://towardsdatascience.com/reinforcement-learning-w-keras-openai-dqns-1eed3a5338c\n",
    "class DQNAgent:\n",
    "    def __init__(self, env, run):\n",
    "        self.run = run\n",
    "        self.history = []\n",
    "        self.env     = env\n",
    "        self.memory  = deque(maxlen=10000)\n",
    "        \n",
    "        self.gamma = 0.95\n",
    "        if not run:\n",
    "            self.epsilon = 1.0\n",
    "            self.epsilon_min = 0.0001\n",
    "        else:\n",
    "            self.epsilon = 0.0\n",
    "            self.epsilon_min = 0.0\n",
    "        self.epsilon_decay = 0.999\n",
    "        self.learning_rate = 0.006\n",
    "        self.tau = 0.8\n",
    "        self.batch_size = 30\n",
    "\n",
    "        self.model        = self._create_model()\n",
    "        self.target_model = self._create_model()\n",
    "        print(self.model.summary())\n",
    "\n",
    "    def _create_model(self):\n",
    "        model   = Sequential()\n",
    "        state_shape  = self.env.observation_space.__len__()\n",
    "        model.add(Dense(24, input_dim=state_shape, activation=\"relu\"))\n",
    "        model.add(Dense(24, activation=\"relu\"))\n",
    "        model.add(Dense(self.env.action_space.n, activation=\"linear\"))\n",
    "        model.compile(loss=Huber(), optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def act(self, state):\n",
    "        self.epsilon *= self.epsilon_decay\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon)\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        return np.argmax(self.model.predict(state)[0])\n",
    "\n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.memory.append([state, action, reward, new_state, done])\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.batch_size or self.run: \n",
    "            return\n",
    "\n",
    "        samples = random.sample(self.memory, self.batch_size)\n",
    "        for sample in samples:\n",
    "            state, action, reward, new_state, done = sample\n",
    "            target = self.target_model.predict(state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                Q_future = max(self.target_model.predict(new_state)[0])\n",
    "                target[0][action] = reward + Q_future * self.gamma\n",
    "            history = self.model.fit(state, target, epochs=1, verbose=0)\n",
    "            self.history.append(history.history['loss'][0])\n",
    "        self.target_train()\n",
    "\n",
    "    def target_train(self):\n",
    "        weights = self.model.get_weights()\n",
    "        target_weights = self.target_model.get_weights()\n",
    "        for i in range(len(target_weights)):\n",
    "            target_weights[i] = weights[i] * self.tau + target_weights[i] * (1 - self.tau)\n",
    "        self.target_model.set_weights(target_weights)\n",
    "\n",
    "    def graph(self):\n",
    "        plt.plot(self.history)\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.show()\n",
    "        \n",
    "    def load(self, path):\n",
    "        if os.path.exists(path):\n",
    "            self.model.load_weights(path)\n",
    "            self.target_model.load_weights(path)\n",
    "        else:\n",
    "            print(\"Found no existing weights:\", path)\n",
    "\n",
    "    def save(self, path):\n",
    "        self.target_model.save_weights(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_99 (Dense)             (None, 24)                240       \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 6)                 150       \n",
      "=================================================================\n",
      "Total params: 990\n",
      "Trainable params: 990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Running 100 episodes\n",
      "Run: 1, exploration: 0.9636582956114175, score: 1503 : [7, 4, 8, 7, 6, 5]\n",
      "Run: 2, exploration: 0.9502544225688344, score: -1014 : [2, 5, 1, 4, 0, 2]\n",
      "Run: 3, exploration: 0.9493041681462656, score: -501 : [0, 0, 0, 0, 0, 1]\n",
      "Run: 4, exploration: 0.9483548639781193, score: -501 : [0, 0, 0, 0, 0, 1]\n",
      "Run: 5, exploration: 0.9436225637280606, score: -505 : [1, 1, 0, 2, 0, 1]\n",
      "Run: 6, exploration: 0.9389138777035492, score: -515 : [0, 1, 1, 1, 1, 1]\n",
      "Run: 7, exploration: 0.9360999518731578, score: -1003 : [1, 0, 1, 1, 0, 0]\n",
      "Run: 8, exploration: 0.9342286880693633, score: -502 : [0, 1, 0, 0, 0, 1]\n",
      "Run: 9, exploration: 0.9323611649219127, score: -502 : [0, 0, 0, 1, 0, 1]\n",
      "Run: 10, exploration: 0.9295668775782806, score: -503 : [0, 2, 0, 0, 0, 1]\n",
      "Run: 11, exploration: 0.9102399514140735, score: -1061 : [3, 1, 6, 5, 4, 2]\n",
      "Run: 12, exploration: 0.9056978449586682, score: -1015 : [1, 1, 2, 0, 1, 0]\n",
      "Run: 13, exploration: 0.8666920568517111, score: -1024 : [7, 6, 5, 9, 8, 9]\n",
      "Run: 14, exploration: 0.862367254825433, score: -515 : [0, 0, 1, 2, 1, 1]\n",
      "Run: 15, exploration: 0.8563487636013172, score: -417 : [0, 2, 0, 3, 1, 1]\n",
      "Run: 16, exploration: 0.8546369224228781, score: -502 : [0, 0, 0, 1, 0, 1]\n",
      "Run: 17, exploration: 0.8537822855004553, score: -501 : [0, 0, 0, 0, 0, 1]\n",
      "Run: 18, exploration: 0.8153791427799216, score: -1116 : [6, 10, 11, 8, 7, 4]\n",
      "Run: 19, exploration: 0.8145637636371417, score: -501 : [0, 0, 0, 0, 0, 1]\n",
      "Run: 20, exploration: 0.7984263308107633, score: -1050 : [2, 3, 8, 3, 3, 1]\n",
      "Run: 21, exploration: 0.7392263587988196, score: -707 : [12, 10, 16, 9, 13, 17]\n",
      "Run: 22, exploration: 0.7384871324400207, score: -1001 : [1, 0, 0, 0, 0, 0]\n",
      "Run: 23, exploration: 0.7340672721936974, score: -1016 : [2, 0, 0, 2, 1, 1]\n",
      "Run: 24, exploration: 0.7311354045730207, score: -1004 : [1, 0, 0, 3, 0, 0]\n",
      "Run: 25, exploration: 0.7282152468433455, score: -504 : [0, 2, 1, 0, 0, 1]\n",
      "Run: 26, exploration: 0.7253067522353204, score: -504 : [0, 0, 0, 3, 0, 1]\n",
      "Run: 27, exploration: 0.65297715036201, score: -1135 : [16, 17, 14, 17, 13, 28]\n",
      "Run: 28, exploration: 0.6516718490384363, score: -502 : [0, 0, 1, 0, 0, 1]\n",
      "Run: 29, exploration: 0.6484199999982736, score: -515 : [0, 2, 1, 0, 1, 1]\n",
      "Run: 30, exploration: 0.6186348025557711, score: -617 : [13, 9, 3, 8, 7, 7]\n",
      "Run: 31, exploration: 0.6180161677532153, score: -501 : [0, 0, 0, 0, 0, 1]\n",
      "Run: 32, exploration: 0.6149322608990545, score: -1005 : [2, 1, 1, 0, 0, 1]\n",
      "Run: 33, exploration: 0.6137030113095173, score: -502 : [0, 0, 1, 0, 0, 1]\n",
      "Run: 34, exploration: 0.6130893082982078, score: -501 : [0, 0, 0, 0, 0, 1]\n",
      "Run: 35, exploration: 0.6057725659163237, score: -522 : [2, 2, 1, 4, 1, 2]\n",
      "Run: 36, exploration: 0.6045616265570569, score: -502 : [0, 0, 1, 0, 0, 1]\n",
      "Run: 37, exploration: 0.6039570649304998, score: -501 : [0, 0, 0, 0, 0, 1]\n",
      "Run: 38, exploration: 0.6033531078655693, score: -501 : [0, 0, 0, 0, 0, 1]\n",
      "Run: 39, exploration: 0.5676313011014509, score: -501 : [7, 12, 7, 18, 4, 13]\n",
      "Run: 40, exploration: 0.5625430065087982, score: -1029 : [3, 0, 0, 1, 2, 3]\n",
      "Run: 41, exploration: 0.5536095095627305, score: -936 : [3, 1, 5, 5, 2, 0]\n",
      "Run: 42, exploration: 0.5525028441531146, score: -502 : [0, 0, 0, 1, 0, 1]\n",
      "Run: 43, exploration: 0.54427306365317, score: -525 : [5, 0, 2, 3, 1, 4]\n",
      "Run: 44, exploration: 0.5345589798201541, score: -1028 : [4, 1, 2, 2, 1, 8]\n",
      "Run: 45, exploration: 0.5297671482893791, score: -509 : [1, 2, 1, 4, 0, 1]\n",
      "Run: 46, exploration: 0.5287081437599487, score: -502 : [0, 0, 0, 1, 0, 1]\n",
      "Run: 47, exploration: 0.5271236049243919, score: -503 : [0, 0, 0, 2, 0, 1]\n",
      "Run: 48, exploration: 0.508984494702897, score: -535 : [2, 3, 6, 2, 0, 22]\n",
      "Run: 49, exploration: 0.508475510208194, score: -501 : [0, 0, 0, 0, 0, 1]\n",
      "Run: 50, exploration: 0.5074590676632879, score: -502 : [0, 0, 0, 1, 0, 1]\n",
      "Run: 51, exploration: 0.31111772878333877, score: 731 : [85, 88, 91, 120, 28, 77]\n",
      "Run: 52, exploration: 0.308946427275922, score: -527 : [0, 0, 3, 1, 2, 1]\n",
      "Run: 53, exploration: 0.3034324092307786, score: -528 : [0, 1, 11, 4, 1, 1]\n",
      "Run: 54, exploration: 0.2903644524887822, score: -604 : [2, 8, 9, 18, 6, 1]\n",
      "Run: 55, exploration: 0.27454326105180193, score: -616 : [2, 13, 13, 11, 16, 1]\n",
      "Run: 56, exploration: 0.2637729867768368, score: 1440 : [3, 4, 11, 9, 2, 11]\n",
      "Run: 57, exploration: 0.23937714058612394, score: -617 : [0, 55, 21, 18, 2, 1]\n",
      "Run: 58, exploration: 0.23770651915214663, score: -507 : [0, 0, 2, 4, 0, 1]\n",
      "Run: 59, exploration: 0.23699411247654112, score: -503 : [0, 0, 0, 2, 0, 1]\n",
      "Run: 60, exploration: 0.2346348076972527, score: -510 : [0, 2, 6, 1, 0, 1]\n",
      "Run: 61, exploration: 0.2295266829410795, score: -532 : [1, 6, 2, 11, 1, 1]\n",
      "Run: 62, exploration: 0.11224248209992274, score: -1785 : [190, 83, 112, 78, 17, 235]\n",
      "Run: 63, exploration: 0.1024747082563476, score: -601 : [1, 16, 30, 42, 1, 1]\n",
      "Run: 64, exploration: 0.09669744692213977, score: -558 : [0, 44, 5, 8, 0, 1]\n",
      "Run: 65, exploration: 0.09516183749001367, score: -1016 : [1, 13, 2, 0, 0, 0]\n",
      "Run: 66, exploration: 0.09253296740380676, score: -528 : [0, 13, 7, 7, 0, 1]\n",
      "Run: 67, exploration: 0.07605577251287458, score: -766 : [2, 40, 62, 74, 17, 1]\n",
      "Run: 68, exploration: 0.06745136906817856, score: -1120 : [7, 43, 32, 34, 0, 4]\n",
      "Run: 69, exploration: 0.05494344105065345, score: -1225 : [29, 68, 56, 46, 2, 4]\n",
      "Run: 70, exploration: 0.042528575988743995, score: -756 : [67, 42, 25, 24, 0, 98]\n",
      "Run: 71, exploration: 0.042231767569906, score: -507 : [0, 5, 0, 1, 0, 1]\n",
      "Run: 72, exploration: 0.041727764385609184, score: -1012 : [2, 7, 0, 3, 0, 0]\n",
      "Run: 73, exploration: 0.028759858009598873, score: -1422 : [20, 98, 126, 108, 5, 15]\n",
      "Run: 74, exploration: 0.020859719207691117, score: 1169 : [87, 81, 75, 22, 1, 55]\n",
      "Run: 75, exploration: 0.01866713426479925, score: -1111 : [25, 17, 24, 16, 0, 29]\n",
      "Run: 76, exploration: 0.013337723044094777, score: -836 : [45, 106, 80, 67, 0, 38]\n",
      "Run: 77, exploration: 0.012361147829929142, score: -1076 : [9, 33, 21, 2, 0, 11]\n",
      "Run: 78, exploration: 0.006660863348529981, score: -1058 : [131, 139, 90, 151, 4, 103]\n",
      "Run: 79, exploration: 0.005978651686379799, score: -1108 : [13, 39, 39, 10, 0, 7]\n",
      "Run: 80, exploration: 0.00503850552347926, score: -681 : [44, 7, 42, 59, 1, 18]\n",
      "Run: 81, exploration: 0.0019052689710214068, score: -1982 : [71, 295, 312, 241, 1, 52]\n",
      "Run: 82, exploration: 0.0018825310729036647, score: -922 : [2, 4, 0, 5, 1, 0]\n",
      "Run: 83, exploration: 0.0013223898194985465, score: -1353 : [56, 67, 89, 67, 0, 74]\n",
      "Run: 84, exploration: 0.0011669319355299846, score: -1125 : [15, 28, 26, 56, 0, 0]\n",
      "Run: 85, exploration: 0.0011657650035944546, score: -1001 : [1, 0, 0, 0, 0, 0]\n",
      "Run: 86, exploration: 0.0011564714597844976, score: -1008 : [3, 0, 0, 5, 0, 0]\n",
      "Run: 87, exploration: 0.0011415272056557154, score: -1013 : [12, 0, 1, 0, 0, 0]\n",
      "Run: 88, exploration: 0.00041931459644041827, score: -1001 : [44, 314, 351, 279, 0, 13]\n",
      "Run: 89, exploration: 0.0003446479287649894, score: -696 : [31, 38, 84, 26, 0, 17]\n",
      "Run: 90, exploration: 0.0003334546548446095, score: 1467 : [5, 14, 5, 8, 0, 1]\n",
      "Run: 91, exploration: 0.00031402634027427904, score: -1060 : [3, 25, 22, 10, 0, 0]\n",
      "Run: 92, exploration: 0.00017683015173258055, score: -1574 : [82, 154, 142, 146, 0, 50]\n",
      "Run: 93, exploration: 0.00013483530716017816, score: 1229 : [56, 55, 49, 58, 0, 53]\n",
      "Run: 94, exploration: 0.0001, score: -1524 : [51, 143, 157, 162, 0, 11]\n",
      "Run: 95, exploration: 0.0001, score: -1200 : [19, 41, 69, 65, 0, 6]\n",
      "Run: 96, exploration: 0.0001, score: -1179 : [31, 32, 42, 54, 0, 20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 97, exploration: 0.0001, score: -1190 : [26, 21, 56, 65, 0, 22]\n",
      "Run: 98, exploration: 0.0001, score: -1102 : [34, 20, 11, 16, 0, 21]\n",
      "Run: 99, exploration: 0.0001, score: -1006 : [1, 3, 0, 2, 0, 0]\n",
      "Run: 100, exploration: 0.0001, score: -1001 : [1, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-f\", \"--filename\", help=\"The name of the model to load/save\", default=\"model\")\n",
    "parser.add_argument(\"-r\", \"--run\", help=\"Run a trained model\", action=\"store_true\")\n",
    "parser.add_argument(\"-e\", \"--episodes\", type=int, help=\"Number of episodes to run/train\", default=100)\n",
    "parser.add_argument(\"--maxsteps\", type=int, help=\"The max steps in an episode. Prevents bot from looping\", default=1000)\n",
    "args = parser.parse_args()\n",
    "\n",
    "weights_file = re.sub(r\"\\.h5$\", \"\", args.filename) + \".h5\"\n",
    "\n",
    "def train():\n",
    "    env = Wumpus() \n",
    "    observation_space = env.observation_space.__len__()\n",
    "    action_space = env.action_space.n\n",
    "    agent = DQNAgent(env, run=args.run)\n",
    "    scores = []\n",
    "    print(\"Running\", args.episodes, \"episodes\")\n",
    "    run = 0\n",
    "    for _ in range(args.episodes):\n",
    "        run += 1\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, observation_space])\n",
    "        score = 0\n",
    "        step = 0\n",
    "        action_count = [0] * env.action_space.n\n",
    "        while True:\n",
    "            step += 1\n",
    "            # print(\"Step:\",step)\n",
    "            # env.render()\n",
    "            action = agent.act(state)\n",
    "            action_count[action] += 1\n",
    "            state_next, reward, terminal, info = env.step(action)\n",
    "            score += reward\n",
    "\n",
    "            state_next = np.reshape(state_next, [1, observation_space])\n",
    "            agent.remember(state, action, reward, state_next, terminal)\n",
    "            state = state_next\n",
    "\n",
    "            agent.replay()\n",
    "\n",
    "            if terminal or step > args.maxsteps:\n",
    "                print(\"Run: \" + str(run) + \", exploration: \" + str(agent.epsilon) + \", score: \" + str(score) + \" : \" + str(action_count))\n",
    "                scores.append(score)\n",
    "                break\n",
    "    agent.graph()\n",
    "    plt.plot(scores)\n",
    "    plt.title('score')\n",
    "    plt.ylabel('score')\n",
    "    plt.xlabel('episode')\n",
    "    plt.show()\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "For a majority of the project, the results were not too great. There often were a few emergent behaviors that often showed up. When there was no cap on the number of actions the agent could take, they would stay in one spot performing a useless action so that the game never ended. As mentioned before, another common behavior was to exit the cave immediately. When testing with just the exit and gold, the agent would run laps around the outer perimeter since that has a higher chance of gold. Most of the malignant behaviors were solved by adding the additional information of player position, direction, and gold status to the oberseved state. While this did feel a little bit like cheating, I think the amount of training I would have to do otherwise would be unreasonable. I wanted a system that I could iterate fast so that I could tune hyper parameters and see there effects without waiting for hours. However, it is the nature of the problems that you need to train the agent a lot and have a long exploring phase so that the agent can understand all the objectives in the game and their reward. Given the right conditions, my DQN agent could end up doing well near the end of the training, but often it would end poorly. With the new changes I actually began to see consistent runs that performed better than a random agent, which I will deem a success. The agent was usually not very efficient, but it seemed to understand the goal of \"get the gold and exit.\" \n",
    "\n",
    "I wish I could have spent more time on this problem experimenting with different model structures, and I also wish I had implemented a Bayesian agent as a baseline performance measure for my DQN agent.\n",
    "\n",
    "## Implications\n",
    "I don't think are many social or ehtical implications within my specific project, but some things did cross my mind while working on the project. The main thing that I was thinking was how this problem could already be solved with a Bayesian algorithm, and it would probably work better too. I spent so much time and energy training this bot when I could have simply solved the problem in a more efficient manner. I even began to work on a Bayesian agent but ran out of time. The main takeaway for me was that if there are simpler methods that already do the job well, you mind as well use those instead. A lot of resources are poured into training neural networks, and from an ecological standpoint, it may not be the best use of resources.\n",
    "\n",
    "## References\n",
    "1. [OpenAI Gym](https://openai.com/blog/openai-baselines-dqn/)\n",
    "2. [Reinforcement Learning w/ Keras + OpenAI: DQNs](https://towardsdatascience.com/reinforcement-learning-w-keras-openai-dqns-1eed3a5338c)\n",
    "3. [Reinforcement Learning (DQN) Tutorial](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html)\n",
    "4. [Artifical Intelligence: A Modern Approach](http://aima.cs.berkeley.edu/)\n",
    "5. [Deep Q-Learning with Recurrent Neural Networks](http://cs229.stanford.edu/proj2016/report/ChenYingLaird-DeepQLearningWithRecurrentNeuralNetwords-report.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
