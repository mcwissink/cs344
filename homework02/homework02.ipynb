{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1\n",
    "\n",
    "Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'do': 0.1794871794871795, 'i': 0.39622641509433965, 'like': 0.30434782608695654, 'green': 0.01, 'eggs': 0.01, 'and': 0.01, 'ham': 0.01, 'am': 0.99, 'spam': 0.99, 'not': 0, 'that': 0, 'spamiam': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy\n",
    "\n",
    "# Define the corpuses\n",
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "\n",
    "def make_spam_filter(good_corpus, bad_corpus):\n",
    "    good_corpus_flat = list(map(lambda x: x.lower(), numpy.concatenate(good_corpus)))\n",
    "    bad_corpus_flat = list(map(lambda x: x.lower(), numpy.concatenate(bad_corpus)))\n",
    "    # Create the occurence hashes for each corpus\n",
    "    good_map = Counter(good_corpus_flat)\n",
    "    bad_map = Counter(bad_corpus_flat)\n",
    "\n",
    "    # Token probability function taken from reading\n",
    "    def calc_token_probability(token):\n",
    "        g = 2 * (good_map.get(token) or 0)\n",
    "        b = bad_map.get(token) or 0\n",
    "        ngood = len(good_map)\n",
    "        nbad = len(bad_map)\n",
    "        if g + b > 1:\n",
    "            return max(0.01, min(0.99, min(1.0, b / nbad) / (min(1.0, g / ngood) + min(1.0, b/ nbad))))\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # Table of all the token probabilities\n",
    "    token_probability = dict(map(\n",
    "        lambda x: (x, calc_token_probability(x)), good_corpus_flat + bad_corpus_flat\n",
    "    ))\n",
    "    print(token_probability)\n",
    "    def get_token_probability(token):\n",
    "        return token_probability.get(token) or 0.5\n",
    "    \n",
    "    def spam_probability(message):\n",
    "        # Get 15 most interesting tokens\n",
    "        # token_interest = dict(map(\n",
    "        #    lambda x: (x, abs(tokenProbability(x) - 0.5)), message\n",
    "        # ))\n",
    "        probs = list(map(get_token_probability, message))\n",
    "        prod = numpy.prod(probs)\n",
    "        return prod / (prod + numpy.prod(list(map(lambda x: 1 - x, probs))))\n",
    "        \n",
    "    \n",
    "    return spam_probability\n",
    "\n",
    "check_spam = make_spam_filter(ham_corpus, spam_corpus)\n",
    "\n",
    "check_spam(\"spam is awesome\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2\n",
    "\n",
    "Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello Problem 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
