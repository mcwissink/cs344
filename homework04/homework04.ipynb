{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " # Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to say whether deep neural networks are complete busts since they do currently solve many practical problems. Unlike expert systems, that required extensive knowledge on the subject, neural networks can be created given enough observational data. They can also deal with non-linearity unlike perceptrons.\n",
    "\n",
    "While neural networks are powerful, there is a large initial cost of data and training that can render them impractical. Classification models are also limited in a sense that they will only ever have a fixed classifcation. For example, the MNIST can only classify if a given image is a 1-9, but it won't tell you that it is an a-z unless you retrain the model.\n",
    "\n",
    "Neural networks are good at what they do, but they don't have limitless potential. It's hard to speculate into the future, but I do believe neural networks will be relevant, but probably applied in specific domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hand-compute a single, complete back-propagation cycle. Use the example network from class and compute the updated weight values for the first gradient descent iteration for the XOR example, i.e., [1, 1] → 0. Use the same initial weights we used in the class example but assume the identity function as the activation function (f(x) = x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use the weights from class\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "&\\begin{bmatrix}\n",
    "w_{i_1,h_1} & w_{i_1,h_2} \\\\\n",
    "w_{i_2,h_1} & w_{i_2,h_2}\n",
    "\\end{bmatrix}\n",
    "\\leftarrow\n",
    "\\begin{bmatrix}\n",
    "0.11 & 0.12 \\\\\n",
    "0.21 & 0.08\n",
    "\\end{bmatrix} \\\\\n",
    "&\\begin{bmatrix}\n",
    "w_{h_1, o_1} \\\\ \n",
    "w_{h_2, o_1} \n",
    "\\end{bmatrix}\n",
    "\\leftarrow\n",
    "\\begin{bmatrix}\n",
    "0.14 \\\\\n",
    "0.15\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "2. Compute the output for one sample (XOR: `[1, 1]` &rarr; `1`).\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "o_j &= \n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\ \n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "0.11 & 0.12 \\\\\n",
    "0.21 & 0.08\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "0.14 \\\\\n",
    "0.15\n",
    "\\end{bmatrix}\n",
    "\\\\ &=\n",
    "\\begin{bmatrix}\n",
    "1 * 0.11 + 1 * 0.21 & 1 * 0.12 + 1 * 0.08\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "0.14 \\\\ \n",
    "0.15\n",
    "\\end{bmatrix}\n",
    "\\\\ &=\n",
    "\\begin{bmatrix}\n",
    "0.32 & 0.2\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "0.14 \\\\ \n",
    "0.15 \n",
    "\\end{bmatrix}\n",
    "\\\\ &=\n",
    "\\begin{bmatrix}\n",
    "0.32 * 0.14 + 0.2 * 0.15\n",
    "\\end{bmatrix}\n",
    "\\\\ &= 0.0748\n",
    "\\end{aligned}\n",
    "\\\\\n",
    "$\n",
    "\n",
    "3. Compute the error (and more importantly, the delta).\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "L_2Error &= (0 - 0.0748)^2 \\\\\n",
    "&= 0.00559504\\\\\n",
    "\\Delta_{o_1} &= (0 - 0.0748) \\\\\n",
    "&= -0.0748 \\\\\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "4. Backpropagate updates back through the network, assuming:\n",
    "$learning\\_rate = 0.05$; \n",
    "identity activation functions for all nodes.\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "w_{h_1, o_1} \\\\ \n",
    "w_{h_2, o_1}\n",
    "\\end{bmatrix} &\\leftarrow \n",
    "\\begin{bmatrix}\n",
    "0.14 \\\\ \n",
    "0.15 \n",
    "\\end{bmatrix} + 0.05 \\cdot \n",
    "\\begin{bmatrix}\n",
    "0.32 \\\\ \n",
    "0.2 \n",
    "\\end{bmatrix} \\cdot 1.0 \\cdot -0.0748 \\\\\\\\\n",
    "&= \n",
    "\\begin{bmatrix}\n",
    "0.14 \\\\ \n",
    "0.15 \n",
    "\\end{bmatrix} + \n",
    "\\begin{bmatrix}\n",
    "0.05 * 0.32 * 1.0 * -0.0748 \\\\\n",
    "0.05 * 0.2 * 1.0 * -0.0748 \n",
    "\\end{bmatrix} \\\\\n",
    "&= \n",
    "\\begin{bmatrix}\n",
    "0.14 \\\\ \n",
    "0.15 \n",
    "\\end{bmatrix} +\n",
    "\\begin{bmatrix}\n",
    "-0.0011968 \\\\\n",
    "-0.000748 \n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "0.1388032 \\\\ \n",
    "0.149252\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}$\n",
    "\n",
    "$\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "w_{i_1,h_1} & w_{i_1,h_2} \\\\ \n",
    "w_{i_2,h_1} & w_{i_2,h_2}\n",
    "\\end{bmatrix} &\\leftarrow \n",
    "\\begin{bmatrix}\n",
    "0.11 & 0.12 \\\\\n",
    "0.21 & 0.08\n",
    "\\end{bmatrix} + 0.05 \\cdot\n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\ \n",
    "1 & 1\n",
    "\\end{bmatrix} \\cdot 1.0 \\odot\n",
    "\\begin{bmatrix}\n",
    "0.14 & 0.15 \\\\ \n",
    "0.14 & 0.15\n",
    "\\end{bmatrix} \\cdot -0.0748 \\\\ &=\n",
    "\\begin{bmatrix}\n",
    "0.11 & 0.12 \\\\\n",
    "0.21 & 0.08\n",
    "\\end{bmatrix} + \n",
    "\\begin{bmatrix}\n",
    "0.05 * 1 * 1.0 & 0.05 * 1 * 1.0 \\\\ \n",
    "0.05 * 1 * 1.0 & 0.05 * 1 * 1.0 \\\\ \n",
    "\\end{bmatrix} \\odot \n",
    "\\begin{bmatrix}\n",
    "0.14 * -0.0748 & 0.15 * -0.0748\\\\ \n",
    "0.14 * -0.0748 & 0.15 * -0.0748 \n",
    "\\end{bmatrix} \\\\ &=\n",
    "\\begin{bmatrix}\n",
    "0.11 & 0.12 \\\\\n",
    "0.21 & 0.08\n",
    "\\end{bmatrix} + \n",
    "\\begin{bmatrix}\n",
    "0.05 & 0.05 \\\\ \n",
    "0.05 & 0.05 \n",
    "\\end{bmatrix} \\odot \n",
    "\\begin{bmatrix}\n",
    "-0.010472 & -0.01122 \\\\\n",
    "-0.010472 & -0.01122\n",
    "\\end{bmatrix} \\\\ &=\n",
    "\\begin{bmatrix}\n",
    "0.11 & 0.12 \\\\\n",
    "0.21 & 0.08\n",
    "\\end{bmatrix} + \n",
    "\\begin{bmatrix}\n",
    "0.05 * -0.010472 & 0.05 * -0.01122 \\\\\n",
    "0.05 * -0.010472 & 0.05 * -0.01122\n",
    "\\end{bmatrix} \\\\ &=\n",
    "\\begin{bmatrix}\n",
    "0.11 & 0.12 \\\\\n",
    "0.21 & 0.08\n",
    "\\end{bmatrix} +     \n",
    "\\begin{bmatrix}\n",
    "-0.0005236 & -0.000561 \\\\\n",
    "-0.0005236 & -0.000561\n",
    "\\end{bmatrix} \\\\ &= \n",
    "\\begin{bmatrix}\n",
    "0.1094764 & 0.119439 \\\\\n",
    "0.2094764 & 0.079439\n",
    "\\end{bmatrix}  \n",
    "\\end{aligned}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Keras-based ConvNet for Keras’s Fashion MNIST dataset (fashion_mnist). Experiment with different network architectures, submit your most performant network, and report the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                51232     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 89,130\n",
      "Trainable params: 89,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 2 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 27s 455us/step - loss: 0.1795 - accuracy: 0.9453\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 30s 496us/step - loss: 0.0518 - accuracy: 0.9844\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 27s 454us/step - loss: 0.0361 - accuracy: 0.9895\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 27s 456us/step - loss: 0.0269 - accuracy: 0.9920\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0215 - accuracy: 0.9932\n",
      "10000/10000 [==============================] - 2s 154us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.030065006303491827, 0.991100013256073]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results: [0.027693460536356726, 0.9911999702453613]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
